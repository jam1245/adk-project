# =============================================================================
# LLM Provider Configuration
# =============================================================================
# Set these to switch between providers. Only change what you need.
# The default (no env vars set) uses Anthropic Claude 3 Haiku.

# LLM model string (LiteLLM format: "provider/model-name")
# Examples:
#   anthropic/claude-3-haiku-20240307   (default)
#   openai/gpt-4o
#   openai/llama-3.3-70b-instruct      (for OpenAI-compatible endpoints)
LLM_MODEL=anthropic/claude-3-haiku-20240307

# Custom API base URL (only needed for internal/self-hosted endpoints)
# Example: https://api.ai.us.lmco.com/v1
# LLM_API_BASE=

# API key override (if not set, LiteLLM uses provider-specific env vars below)
# LLM_API_KEY=

# SSL verification (set to "false" for corporate endpoints with self-signed certs)
# LLM_SSL_VERIFY=true

# =============================================================================
# Provider-specific API keys (used when LLM_API_KEY is not set)
# =============================================================================
ANTHROPIC_API_KEY=your-anthropic-api-key-here
# OPENAI_API_KEY=your-openai-api-key-here

# =============================================================================
# Application Settings
# =============================================================================
LOG_LEVEL=INFO
MAX_REFINEMENT_ITERATIONS=3
